#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨OpenAI Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«å¹¶ç”Ÿæˆç»“æ„åŒ–JSONæ–‡ä»¶
"""

import os
import sys
import json
import argparse
from pathlib import Path
import ssl
import urllib.request
import time

# ç»•è¿‡SSLè¯ä¹¦éªŒè¯
ssl._create_default_https_context = ssl._create_unverified_context

import whisper


def transcribe_audio(audio_file, speaker_name, model):
    """
    ä½¿ç”¨Whisperè½¬å½•éŸ³é¢‘æ–‡ä»¶
    
    Args:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        speaker_name: è¯´è¯äººåç§° ("è‡ªå·±" æˆ– "å¯¹æ–¹")
        model: Whisperæ¨¡å‹
    
    Returns:
        list: è½¬å½•ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«start, end, text, speaker
    """
    print(f"ğŸµ æ­£åœ¨è½¬å½• {speaker_name} çš„éŸ³é¢‘: {audio_file.name}")
    
    # è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
    file_size = os.path.getsize(audio_file) / (1024 * 1024)  # MB
    print(f"ğŸ“Š éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size:.1f} MB")
    
    # ä½¿ç”¨Whisperè¿›è¡Œè½¬å½•ï¼ŒåŒ…å«æ—¶é—´æˆ³
    print(f"ğŸ”„ å¼€å§‹Whisperè½¬å½•å¤„ç†...")
    start_time = time.time()
    
    try:
        result = model.transcribe(
            str(audio_file),
            word_timestamps=True,
            language='en',
            beam_size=5,
            temperature=0.4,
            condition_on_previous_text=False,
            no_speech_threshold=0.2,
            logprob_threshold=-2.0
        )
        
        processing_time = time.time() - start_time
        print(f"â±ï¸ Whisperå¤„ç†è€—æ—¶: {processing_time:.1f}ç§’")
        
    except Exception as e:
        print(f"âŒ Whisperè½¬å½•å¤±è´¥: {e}")
        raise e
    
    print(f"ğŸ“ å¼€å§‹å¤„ç†è½¬å½•ç»“æœ...")
    transcriptions = []
    
    # å¤„ç†segmentsï¼ˆå¥å­çº§åˆ«çš„æ—¶é—´æˆ³ï¼‰
    total_segments = len(result.get('segments', []))
    print(f"ğŸ“‹ æ£€æµ‹åˆ° {total_segments} ä¸ªè¯­éŸ³æ®µè½")
    
    for i, segment in enumerate(result['segments']):
        if i % 10 == 0 and i > 0:  # æ¯10ä¸ªæ®µè½æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            print(f"ğŸ“ˆ å¤„ç†è¿›åº¦: {i}/{total_segments} ({i/total_segments*100:.1f}%)")
        
        text = segment['text'].strip()
        # è¿‡æ»¤æ‰ç©ºçš„æˆ–å¤ªçŸ­çš„æ–‡æœ¬
        if text and len(text) > 0:
            transcriptions.append({
                "start": round(segment['start'], 2),
                "end": round(segment['end'], 2),
                "text": text,
                "speaker": speaker_name
            })
    
    print(f"âœ… {speaker_name} è½¬å½•å®Œæˆï¼Œå…± {len(transcriptions)} ä¸ªç‰‡æ®µ")
    return transcriptions


def merge_and_sort_transcriptions(transcriptions_list):
    """
    åˆå¹¶å¤šä¸ªè½¬å½•ç»“æœå¹¶æŒ‰æ—¶é—´æˆ³æ’åº
    
    Args:
        transcriptions_list: è½¬å½•ç»“æœåˆ—è¡¨çš„åˆ—è¡¨
    
    Returns:
        list: åˆå¹¶å¹¶æ’åºåçš„è½¬å½•ç»“æœ
    """
    # åˆå¹¶æ‰€æœ‰è½¬å½•ç»“æœ
    all_transcriptions = []
    for transcriptions in transcriptions_list:
        all_transcriptions.extend(transcriptions)
    
    # æŒ‰å¼€å§‹æ—¶é—´æ’åº
    all_transcriptions.sort(key=lambda x: x['start'])
    
    return all_transcriptions


def find_audio_files(recordings_dir):
    """
    æŸ¥æ‰¾æœ€æ–°çš„éŸ³é¢‘æ–‡ä»¶å¯¹
    
    Args:
        recordings_dir: å½•åˆ¶ç›®å½•
    
    Returns:
        tuple: (è‡ªå·±.wavæ–‡ä»¶è·¯å¾„, å¯¹æ–¹.wavæ–‡ä»¶è·¯å¾„) æˆ– (None, None)
    """
    # æŸ¥æ‰¾æ‰€æœ‰çš„éŸ³é¢‘æ–‡ä»¶
    self_files = list(recordings_dir.glob("*_è‡ªå·±.wav"))
    other_files = list(recordings_dir.glob("*_å¯¹æ–¹.wav"))
    
    if not self_files or not other_files:
        return None, None
    
    # è·å–æœ€æ–°çš„æ–‡ä»¶å¯¹ï¼ˆåŸºäºæ–‡ä»¶åä¸­çš„æ—¶é—´æˆ³ï¼‰
    self_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
    other_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
    
    # æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹
    for self_file in self_files:
        base_name = self_file.name.replace("_è‡ªå·±.wav", "")
        other_file = recordings_dir / f"{base_name}_å¯¹æ–¹.wav"
        if other_file.exists():
            return self_file, other_file
    
    return None, None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«å¹¶ç”ŸæˆJSONæ–‡ä»¶")
    parser.add_argument("--self-audio", type=str, help="è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--other-audio", type=str, help="å¯¹æ–¹çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--single-audio", type=str, help="å•ç‹¬è½¬å½•ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--speaker-name", type=str, default="è¯´è¯äºº", help="å•ç‹¬è½¬å½•æ—¶çš„è¯´è¯äººåç§°")
    parser.add_argument("--output", type=str, default="output.json", help="è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", type=str, default="small", help="Whisperæ¨¡å‹å¤§å° (tiny, base, small, medium, large)")
    
    args = parser.parse_args()
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).parent.parent
    recordings_dir = project_root / "recordings"
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å•éŸ³é¢‘æ¨¡å¼
    if args.single_audio:
        # å•éŸ³é¢‘æ¨¡å¼
        single_audio = Path(args.single_audio)
        
        if not single_audio.exists():
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {single_audio}")
            sys.exit(1)
        
        print(f"ğŸ“ å•éŸ³é¢‘è½¬å½•æ¨¡å¼:")
        print(f"  ğŸ¤ éŸ³é¢‘æ–‡ä»¶: {single_audio.name}")
        print(f"  ğŸ‘¤ è¯´è¯äºº: {args.speaker_name}")
        
        # åŠ è½½Whisperæ¨¡å‹
        print(f"\nğŸ¤– åŠ è½½Whisperæ¨¡å‹: {args.model}")
        print(f"â³ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        try:
            model = whisper.load_model(args.model)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            sys.exit(1)
        
        # è½¬å½•éŸ³é¢‘æ–‡ä»¶
        print("\nğŸµ å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        print(f"ğŸ¯ ç›®æ ‡æ–‡ä»¶: {single_audio}")
        print(f"ğŸ‘¤ è¯´è¯äººæ ‡è¯†: {args.speaker_name}")
        print(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹: {args.model}")
        
        try:
            transcriptions = transcribe_audio(single_audio, args.speaker_name, model)
            
            # è¾“å‡ºåˆ°JSONæ–‡ä»¶
            output_path = Path(args.output)
            if not output_path.is_absolute():
                output_path = project_root / output_path
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(transcriptions, f, ensure_ascii=False, indent=2)
            
            print(f"\nâœ… è½¬å½•å®Œæˆï¼")
            print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_path}")
            print(f"ğŸ“Š æ€»è®¡ {len(transcriptions)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœä½œä¸ºé¢„è§ˆ
            if transcriptions:
                print("\nğŸ“ è½¬å½•é¢„è§ˆ:")
                for i, item in enumerate(transcriptions[:5]):
                    print(f"  {i+1}. [{item['start']:.1f}s-{item['end']:.1f}s] {item['speaker']}: {item['text']}")
                
                if len(transcriptions) > 5:
                    print(f"  ... è¿˜æœ‰ {len(transcriptions) - 5} ä¸ªç‰‡æ®µ")
            
        except Exception as e:
            print(f"âŒ è½¬å½•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            sys.exit(1)
        
        return
    
    # åŒéŸ³é¢‘æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    # ç¡®å®šéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    if args.self_audio and args.other_audio:
        self_audio = Path(args.self_audio)
        other_audio = Path(args.other_audio)
    else:
        print("ğŸ” è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„éŸ³é¢‘æ–‡ä»¶...")
        self_audio, other_audio = find_audio_files(recordings_dir)
        
        if not self_audio or not other_audio:
            print("âŒ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶å¯¹")
            print("è¯·ç¡®ä¿recordingsç›®å½•ä¸­æœ‰ *_è‡ªå·±.wav å’Œ *_å¯¹æ–¹.wav æ–‡ä»¶")
            print("æˆ–è€…ä½¿ç”¨ --self-audio å’Œ --other-audio å‚æ•°æŒ‡å®šæ–‡ä»¶è·¯å¾„")
            print("æˆ–è€…ä½¿ç”¨ --single-audio å‚æ•°è½¬å½•å•ä¸ªéŸ³é¢‘æ–‡ä»¶")
            sys.exit(1)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not self_audio.exists():
        print(f"âŒ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self_audio}")
        sys.exit(1)
    
    if not other_audio.exists():
        print(f"âŒ å¯¹æ–¹çš„éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {other_audio}")
        sys.exit(1)
    
    print(f"ğŸ“ æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
    print(f"  ğŸ¤ è‡ªå·±: {self_audio.name}")
    print(f"  ğŸ¤ å¯¹æ–¹: {other_audio.name}")
    
    # åŠ è½½Whisperæ¨¡å‹
    print(f"\nğŸ¤– åŠ è½½Whisperæ¨¡å‹: {args.model}")
    try:
        model = whisper.load_model(args.model)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)
    
    # è½¬å½•éŸ³é¢‘æ–‡ä»¶
    print("\nğŸµ å¼€å§‹è¯­éŸ³è¯†åˆ«...")
    
    try:
        # è½¬å½•è‡ªå·±çš„éŸ³é¢‘
        self_transcriptions = transcribe_audio(self_audio, "è‡ªå·±", model)
        
        # è½¬å½•å¯¹æ–¹çš„éŸ³é¢‘
        other_transcriptions = transcribe_audio(other_audio, "å¯¹æ–¹", model)
        
        # ç”Ÿæˆå•ç‹¬çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_path = Path(args.output)
        if not output_path.is_absolute():
            output_path = project_root / output_path
        
        # ç”Ÿæˆå•ç‹¬æ–‡ä»¶çš„è·¯å¾„
        output_dir = output_path.parent
        output_stem = output_path.stem
        output_suffix = output_path.suffix
        
        self_output_path = output_dir / f"{output_stem}_è‡ªå·±{output_suffix}"
        other_output_path = output_dir / f"{output_stem}_å¯¹æ–¹{output_suffix}"
        
        # ä¿å­˜å•ç‹¬çš„è½¬å½•ç»“æœ
        print("\nğŸ’¾ ä¿å­˜å•ç‹¬è½¬å½•ç»“æœ...")
        
        with open(self_output_path, 'w', encoding='utf-8') as f:
            json.dump(self_transcriptions, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ è‡ªå·±çš„è½¬å½•: {self_output_path}")
        
        with open(other_output_path, 'w', encoding='utf-8') as f:
            json.dump(other_transcriptions, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ å¯¹æ–¹çš„è½¬å½•: {other_output_path}")
        
        # åˆå¹¶å¹¶æ’åº
        print("\nğŸ”„ åˆå¹¶å’Œæ’åºè½¬å½•ç»“æœ...")
        all_transcriptions = merge_and_sort_transcriptions([self_transcriptions, other_transcriptions])
        
        # è¾“å‡ºåˆå¹¶çš„JSONæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(all_transcriptions, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… è½¬å½•å®Œæˆï¼")
        print(f"ğŸ“„ åˆå¹¶æ–‡ä»¶: {output_path}")
        print(f"ğŸ“Š æ€»è®¡ {len(all_transcriptions)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
        print(f"ğŸ“ˆ ç»Ÿè®¡: è‡ªå·± {len(self_transcriptions)} ç‰‡æ®µ, å¯¹æ–¹ {len(other_transcriptions)} ç‰‡æ®µ")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœä½œä¸ºé¢„è§ˆ
        if all_transcriptions:
            print("\nğŸ“ è½¬å½•é¢„è§ˆ:")
            for i, item in enumerate(all_transcriptions[:5]):
                print(f"  {i+1}. [{item['start']:.1f}s-{item['end']:.1f}s] {item['speaker']}: {item['text']}")
            
            if len(all_transcriptions) > 5:
                print(f"  ... è¿˜æœ‰ {len(all_transcriptions) - 5} ä¸ªç‰‡æ®µ")
        
    except Exception as e:
        print(f"âŒ è½¬å½•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 